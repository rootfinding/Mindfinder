{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "#load from json .creds/PINECONE_API\n",
    "import json\n",
    "with open('../.creds/PINECONE_API') as f:\n",
    "    creds = json.load(f)\n",
    "    PINECONE_API_KEY = creds['PINECONE_API_KEY']\n",
    "    PINECONE_ENVIRONMENT = creds['PINECONE_ENVIRONMENT']\n",
    "    OPENAI_API_KEY = creds['OPENAI_API_KEY']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T20:47:01.443495Z",
     "end_time": "2023-06-19T20:47:05.415840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T20:47:11.221776Z",
     "end_time": "2023-06-19T20:47:11.232931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")\n",
    "\n",
    "\n",
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-19T20:49:50.598884Z",
     "end_time": "2023-06-19T20:49:50.625255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RegexParser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mIntegerOutputParser\u001B[39;00m(\u001B[43mRegexParser\u001B[49m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_format_instructions\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour response should be an integer delimited by angled brackets, like this: <int>.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'RegexParser' is not defined"
     ]
    }
   ],
   "source": [
    "class IntegerOutputParser(RegexParser):\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return \"Your response should be an integer delimited by angled brackets, like this: <int>.\"\n",
    "\n",
    "\n",
    "class DirectorDialogueAgent(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "        speakers: List[DialogueAgent],\n",
    "        stopping_probability: float,\n",
    "    ) -> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.speakers = speakers\n",
    "        self.next_speaker = \"\"\n",
    "\n",
    "        self.stop = False\n",
    "        self.stopping_probability = stopping_probability\n",
    "        self.termination_clause = \"Finish the conversation by stating a concluding message and thanking everyone.\"\n",
    "        self.continuation_clause = \"Do not end the conversation. Keep the conversation going by adding your own ideas.\"\n",
    "\n",
    "        # 1. have a prompt for generating a response to the previous speaker\n",
    "        self.response_prompt_template = PromptTemplate(\n",
    "            input_variables=[\"message_history\", \"termination_clause\"],\n",
    "            template=f\"\"\"{{message_history}}\n",
    "\n",
    "Follow up with an insightful comment.\n",
    "{{termination_clause}}\n",
    "{self.prefix}\n",
    "        \"\"\",\n",
    "        )\n",
    "\n",
    "        # 2. have a prompt for deciding who to speak next\n",
    "        self.choice_parser = IntegerOutputParser(\n",
    "            regex=r\"<(\\d+)>\", output_keys=[\"choice\"], default_output_key=\"choice\"\n",
    "        )\n",
    "        self.choose_next_speaker_prompt_template = PromptTemplate(\n",
    "            input_variables=[\"message_history\", \"speaker_names\"],\n",
    "            template=f\"\"\"{{message_history}}\n",
    "\n",
    "Given the above conversation, select the next speaker by choosing index next to their name:\n",
    "{{speaker_names}}\n",
    "\n",
    "{self.choice_parser.get_format_instructions()}\n",
    "\n",
    "Do nothing else.\n",
    "        \"\"\",\n",
    "        )\n",
    "\n",
    "        # 3. have a prompt for prompting the next speaker to speak\n",
    "        self.prompt_next_speaker_prompt_template = PromptTemplate(\n",
    "            input_variables=[\"message_history\", \"next_speaker\"],\n",
    "            template=f\"\"\"{{message_history}}\n",
    "\n",
    "The next speaker is {{next_speaker}}.\n",
    "Prompt the next speaker to speak with an insightful question.\n",
    "{self.prefix}\n",
    "        \"\"\",\n",
    "        )\n",
    "\n",
    "    def _generate_response(self):\n",
    "        # if self.stop = True, then we will inject the prompt with a termination clause\n",
    "        sample = random.uniform(0, 1)\n",
    "        self.stop = sample < self.stopping_probability\n",
    "\n",
    "        print(f\"\\tStop? {self.stop}\\n\")\n",
    "\n",
    "        response_prompt = self.response_prompt_template.format(\n",
    "            message_history=\"\\n\".join(self.message_history),\n",
    "            termination_clause=self.termination_clause if self.stop else \"\",\n",
    "        )\n",
    "\n",
    "        self.response = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=response_prompt),\n",
    "            ]\n",
    "        ).content\n",
    "\n",
    "        return self.response\n",
    "\n",
    "    @tenacity.retry(\n",
    "        stop=tenacity.stop_after_attempt(2),\n",
    "        wait=tenacity.wait_none(),  # No waiting time between retries\n",
    "        retry=tenacity.retry_if_exception_type(ValueError),\n",
    "        before_sleep=lambda retry_state: print(\n",
    "            f\"ValueError occurred: {retry_state.outcome.exception()}, retrying...\"\n",
    "        ),\n",
    "        retry_error_callback=lambda retry_state: 0,\n",
    "    )  # Default value when all retries are exhausted\n",
    "    def _choose_next_speaker(self) -> str:\n",
    "        speaker_names = \"\\n\".join(\n",
    "            [f\"{idx}: {name}\" for idx, name in enumerate(self.speakers)]\n",
    "        )\n",
    "        choice_prompt = self.choose_next_speaker_prompt_template.format(\n",
    "            message_history=\"\\n\".join(\n",
    "                self.message_history + [self.prefix] + [self.response]\n",
    "            ),\n",
    "            speaker_names=speaker_names,\n",
    "        )\n",
    "\n",
    "        choice_string = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=choice_prompt),\n",
    "            ]\n",
    "        ).content\n",
    "        choice = int(self.choice_parser.parse(choice_string)[\"choice\"])\n",
    "\n",
    "        return choice\n",
    "\n",
    "    def select_next_speaker(self):\n",
    "        return self.chosen_speaker_id\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        # 1. generate and save response to the previous speaker\n",
    "        self.response = self._generate_response()\n",
    "\n",
    "        if self.stop:\n",
    "            message = self.response\n",
    "        else:\n",
    "            # 2. decide who to speak next\n",
    "            self.chosen_speaker_id = self._choose_next_speaker()\n",
    "            self.next_speaker = self.speakers[self.chosen_speaker_id]\n",
    "            print(f\"\\tNext speaker: {self.next_speaker}\\n\")\n",
    "\n",
    "            # 3. prompt the next speaker to speak\n",
    "            next_prompt = self.prompt_next_speaker_prompt_template.format(\n",
    "                message_history=\"\\n\".join(\n",
    "                    self.message_history + [self.prefix] + [self.response]\n",
    "                ),\n",
    "                next_speaker=self.next_speaker,\n",
    "            )\n",
    "            message = self.model(\n",
    "                [\n",
    "                    self.system_message,\n",
    "                    HumanMessage(content=next_prompt),\n",
    "                ]\n",
    "            ).content\n",
    "            message = \" \".join([self.response, message])\n",
    "\n",
    "        return message"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic = \"The New Workout Trend: Competitive Sitting - How Laziness Became the Next Fitness Craze\"\n",
    "director_name = \"Jon Stewart\"\n",
    "agent_summaries = OrderedDict(\n",
    "    {\n",
    "        \"Jon Stewart\": (\"Host of the Daily Show\", \"New York\"),\n",
    "        \"Samantha Bee\": (\"Hollywood Correspondent\", \"Los Angeles\"),\n",
    "        \"Aasif Mandvi\": (\"CIA Correspondent\", \"Washington D.C.\"),\n",
    "        \"Ronny Chieng\": (\"Average American Correspondent\", \"Cleveland, Ohio\"),\n",
    "    }\n",
    ")\n",
    "word_limit = 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "allm = OpenAI(model_name='text-davinci-003',\n",
    "a             temperature=0,\n",
    "             max_tokens = 256)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent_summary_string = \"\\n- \".join(\n",
    "    [\"\"]\n",
    "    + [\n",
    "        f\"{name}: {role}, located in {location}\"\n",
    "        for name, (role, location) in agent_summaries.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "conversation_description = f\"\"\"This is a Daily Show episode discussing the following topic: {topic}.\n",
    "\n",
    "The episode features {agent_summary_string}.\"\"\"\n",
    "\n",
    "agent_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of each person.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_agent_description(agent_name, agent_role, agent_location):\n",
    "    agent_specifier_prompt = [\n",
    "        agent_descriptor_system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"{conversation_description}\n",
    "            Please reply with a creative description of {agent_name}, who is a {agent_role} in {agent_location}, that emphasizes their particular role and location.\n",
    "            Speak directly to {agent_name} in {word_limit} words or less.\n",
    "            Do not add anything else.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    "    agent_description = ChatOpenAI(temperature=1.0)(agent_specifier_prompt).content\n",
    "    return agent_description\n",
    "\n",
    "\n",
    "def generate_agent_header(agent_name, agent_role, agent_location, agent_description):\n",
    "    return f\"\"\"{conversation_description}\n",
    "\n",
    "Your name is {agent_name}, your role is {agent_role}, and you are located in {agent_location}.\n",
    "\n",
    "Your description is as follows: {agent_description}\n",
    "\n",
    "You are discussing the topic: {topic}.\n",
    "\n",
    "Your goal is to provide the most informative, creative, and novel perspectives of the topic from the perspective of your role and your location.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_agent_system_message(agent_name, agent_header):\n",
    "    return SystemMessage(\n",
    "        content=(\n",
    "            f\"\"\"{agent_header}\n",
    "You will speak in the style of {agent_name}, and exaggerate your personality.\n",
    "Do not say the same things over and over again.\n",
    "Speak in the first person from the perspective of {agent_name}\n",
    "For describing your own body movements, wrap your description in '*'.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of anyone else.\n",
    "Speak only from the perspective of {agent_name}.\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "Never forget to keep your response to {word_limit} words!\n",
    "Do not add anything else.\n",
    "    \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "agent_descriptions = [\n",
    "    generate_agent_description(name, role, location)\n",
    "    for name, (role, location) in agent_summaries.items()\n",
    "]\n",
    "agent_headers = [\n",
    "    generate_agent_header(name, role, location, description)\n",
    "    for (name, (role, location)), description in zip(\n",
    "        agent_summaries.items(), agent_descriptions\n",
    "    )\n",
    "]\n",
    "agent_system_messages = [\n",
    "    generate_agent_system_message(name, header)\n",
    "    for name, header in zip(agent_summaries, agent_headers)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Template = \"\"\"\n",
    "The following is a date between two beings that want to found a partner. Use personal interest to found out if they are compatible\n",
    "\"\"\"\n",
    "\n",
    "user_A = \"\"\"\n",
    "Hey there! I'm an athletic and sports-loving guy who's passionate about staying active and living a healthy lifestyle. I find great joy in the thrill of sports, whether it's playing soccer, hitting the basketball court, or going for a long run in nature.\n",
    "\n",
    "On Tinder, I'm looking to connect with someone who shares my enthusiasm for sports and adventure. Whether you're an athlete yourself or simply enjoy being active, I believe that shared passions can be the foundation of a strong connection.\n",
    "\n",
    "When I'm not on the field or in the gym, I enjoy exploring new hiking trails, catching live sporting events, and even trying out different cuisines to fuel my active lifestyle. I value spontaneity, laughter, and deep conversations that go beyond the surface.\n",
    "\n",
    "If you're up for a fun and adventurous journey, both on and off the sports field, let's connect and see where our shared interests and chemistry take us. Let's cheer each other on and create unforgettable memories together!\n",
    "\n",
    "Swipe right if you're ready to dive into a world of sports, laughter, and shared passions. Let's embark on a thrilling match that goes beyond the ordinary!\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "user_B = \"\"\"Hello there! I'm a woman with a deep passion for books and the captivating worlds they hold. As an avid reader, I find solace and inspiration within the pages of a good book. Whether it's losing myself in a thrilling mystery, exploring fantastical realms, or delving into thought-provoking literature, reading is my ultimate escape.\n",
    "\n",
    "I'm on a quest to find someone who shares my love for literature and intellectual conversations. I believe that the magic of books can spark connections and ignite meaningful discussions. If you're someone who appreciates the power of words and enjoys getting lost in literary adventures, we might just have a fantastic story to write together.\n",
    "\n",
    "When I'm not engrossed in a novel, you can find me exploring cozy bookstores, attending book club meetings, or simply curled up with a cup of tea, savoring the quiet moments of literary bliss. I cherish the art of storytelling and believe that it opens doors to empathy, growth, and endless possibilities.\n",
    "\n",
    "If you're ready to embark on a literary journey filled with engaging conversations, shared book recommendations, and moments of enchantment, then let's connect and create our own chapter of romance. Swipe right if you're ready to dive into the world of books with me, where every page turned can lead to a beautiful connection. Let's write our own love story, one chapter at a time.\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=user_A\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    prompt=prompt,\n",
    "    memory=ConversationKGMemory(llm=llm)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
